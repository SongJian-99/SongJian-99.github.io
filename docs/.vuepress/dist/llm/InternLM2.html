<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>大语言模型 InternLM2（书生·浦语） | Cleaner 知识库</title>
    <meta name="generator" content="VuePress 1.9.9">
    <link rel="icon" href="/favicon.ico">
    <meta name="description" content="Cleaner 知识库">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="/assets/css/0.styles.b5661576.css" as="style"><link rel="preload" href="/assets/js/app.96fa03ec.js" as="script"><link rel="preload" href="/assets/js/3.6d0f9571.js" as="script"><link rel="preload" href="/assets/js/1.2ae15e76.js" as="script"><link rel="preload" href="/assets/js/30.5d03341f.js" as="script"><link rel="preload" href="/assets/js/9.5e3ddfef.js" as="script"><link rel="prefetch" href="/assets/js/10.477d0751.js"><link rel="prefetch" href="/assets/js/11.b2736a5a.js"><link rel="prefetch" href="/assets/js/12.5d0e7afc.js"><link rel="prefetch" href="/assets/js/13.a721895d.js"><link rel="prefetch" href="/assets/js/14.4c60ce00.js"><link rel="prefetch" href="/assets/js/15.b335caf1.js"><link rel="prefetch" href="/assets/js/16.10fb1625.js"><link rel="prefetch" href="/assets/js/17.ed149370.js"><link rel="prefetch" href="/assets/js/18.85a9d306.js"><link rel="prefetch" href="/assets/js/19.70b36364.js"><link rel="prefetch" href="/assets/js/20.74c0231d.js"><link rel="prefetch" href="/assets/js/21.997b1b0a.js"><link rel="prefetch" href="/assets/js/22.aa6f55ab.js"><link rel="prefetch" href="/assets/js/23.b64ae1ae.js"><link rel="prefetch" href="/assets/js/24.fd42bfea.js"><link rel="prefetch" href="/assets/js/25.66d747a7.js"><link rel="prefetch" href="/assets/js/26.13f62be7.js"><link rel="prefetch" href="/assets/js/27.20a44981.js"><link rel="prefetch" href="/assets/js/28.92ea0fd2.js"><link rel="prefetch" href="/assets/js/29.4d8bb002.js"><link rel="prefetch" href="/assets/js/31.772b66ed.js"><link rel="prefetch" href="/assets/js/32.56ee3f07.js"><link rel="prefetch" href="/assets/js/33.c56621f0.js"><link rel="prefetch" href="/assets/js/34.fcf06f0e.js"><link rel="prefetch" href="/assets/js/35.9eb46021.js"><link rel="prefetch" href="/assets/js/4.53708ea2.js"><link rel="prefetch" href="/assets/js/5.f3e4f405.js"><link rel="prefetch" href="/assets/js/6.577d577f.js"><link rel="prefetch" href="/assets/js/7.e52f8ab3.js"><link rel="prefetch" href="/assets/js/8.12016912.js">
    <link rel="stylesheet" href="/assets/css/0.styles.b5661576.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-7dd95ae2><div data-v-7dd95ae2><div class="password-shadow password-wrapper-out" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>Cleaner 知识库</h3> <p class="description" data-v-59e6cb88>Cleaner 知识库</p> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
          
        <span data-v-59e6cb88>2023 - </span>
        2024
      </a></span></div></div> <div class="hide" data-v-7dd95ae2><header class="navbar" data-v-7dd95ae2><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Cleaner 知识库</span></a> <div class="links"><!----> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/other/navigate.html" class="nav-link"><i class="iconfont icon-navigate"></i>
  导航
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont icon-frontend"></i>
      前端
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/frontend/vuepress/VuePressOne.html" class="nav-link"><i class="undefined"></i>
  VuePress
</a></li><li class="dropdown-item"><!----> <a href="/frontend/vue/jsx.html" class="nav-link"><i class="undefined"></i>
  Vue
</a></li></ul></div></div><div class="nav-item"><a href="/backend/docker/Web.html" class="nav-link"><i class="iconfont icon-docker"></i>
  Docker
</a></div><div class="nav-item"><a href="/backend/mysql/explain.html" class="nav-link"><i class="iconfont icon-mysql"></i>
  MySQL
</a></div><div class="nav-item"><a href="/backend/work/poi.html" class="nav-link"><i class="iconfont icon-work"></i>
  工作
</a></div><div class="nav-item"><a href="/backend/microservice/twelve-factor.html" class="nav-link"><i class="iconfont icon-microservice"></i>
  微服务
</a></div><div class="nav-item"><a href="/llm/basicOne.html" class="nav-link"><i class="iconfont icon-ai"></i>
  大语言模型
</a></div><div class="nav-item"><a href="/tool/git.html" class="nav-link"><i class="iconfont icon-tools"></i>
  工具
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-other"></i>
      其他
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/other/treeholes.html" class="nav-link"><i class="undefined"></i>
  树洞
</a></li></ul></div></div><div class="nav-item"><a href="/timeLine/" class="nav-link"><i class="iconfont reco-date"></i>
  时间轴
</a></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-7dd95ae2></div> <aside class="sidebar" data-v-7dd95ae2><div class="personal-info-wrapper" data-v-1fad0c41 data-v-7dd95ae2><img src="/avator.jpg" alt="author-avatar" class="personal-img" data-v-1fad0c41> <!----> <div class="num" data-v-1fad0c41><div data-v-1fad0c41><h3 data-v-1fad0c41>21</h3> <h6 data-v-1fad0c41>文章</h6></div> <div data-v-1fad0c41><h3 data-v-1fad0c41>13</h3> <h6 data-v-1fad0c41>标签</h6></div></div> <ul class="social-links" data-v-1fad0c41><li class="social-item" data-v-1fad0c41><i class="iconfont reco-github" style="color:#f8b26a;" data-v-1fad0c41></i></li><li class="social-item" data-v-1fad0c41><i class="iconfont reco-juejin" style="color:#f26d6d;" data-v-1fad0c41></i></li></ul> <hr data-v-1fad0c41></div> <nav class="nav-links"><div class="nav-item"><a href="/other/navigate.html" class="nav-link"><i class="iconfont icon-navigate"></i>
  导航
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont icon-frontend"></i>
      前端
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/frontend/vuepress/VuePressOne.html" class="nav-link"><i class="undefined"></i>
  VuePress
</a></li><li class="dropdown-item"><!----> <a href="/frontend/vue/jsx.html" class="nav-link"><i class="undefined"></i>
  Vue
</a></li></ul></div></div><div class="nav-item"><a href="/backend/docker/Web.html" class="nav-link"><i class="iconfont icon-docker"></i>
  Docker
</a></div><div class="nav-item"><a href="/backend/mysql/explain.html" class="nav-link"><i class="iconfont icon-mysql"></i>
  MySQL
</a></div><div class="nav-item"><a href="/backend/work/poi.html" class="nav-link"><i class="iconfont icon-work"></i>
  工作
</a></div><div class="nav-item"><a href="/backend/microservice/twelve-factor.html" class="nav-link"><i class="iconfont icon-microservice"></i>
  微服务
</a></div><div class="nav-item"><a href="/llm/basicOne.html" class="nav-link"><i class="iconfont icon-ai"></i>
  大语言模型
</a></div><div class="nav-item"><a href="/tool/git.html" class="nav-link"><i class="iconfont icon-tools"></i>
  工具
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-other"></i>
      其他
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/other/treeholes.html" class="nav-link"><i class="undefined"></i>
  树洞
</a></li></ul></div></div><div class="nav-item"><a href="/timeLine/" class="nav-link"><i class="iconfont reco-date"></i>
  时间轴
</a></div> <!----></nav> <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>大语言模型基础</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/llm/basicOne.html" class="sidebar-link">发展历程、构建过程及如何使用</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>大语言模型使用</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/llm/InternLM2.html" aria-current="page" class="active sidebar-link">InternLM2（书生·浦语）</a></li></ul></section></li></ul> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>大语言模型 InternLM2（书生·浦语）</h3> <!----> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
          
        <span data-v-59e6cb88>2023 - </span>
        2024
      </a></span></div></div> <div data-v-7dd95ae2><div data-v-7dd95ae2><main class="page"><section style="display:;"><div class="page-title"><h1 class="title">大语言模型 InternLM2（书生·浦语）</h1> <div data-v-8a445198><i class="iconfont reco-account" data-v-8a445198><span data-v-8a445198>Cleaner</span></i> <i class="iconfont reco-date" data-v-8a445198><span data-v-8a445198>2024/1/29</span></i> <!----> <i class="tags iconfont reco-tag" data-v-8a445198><span class="tag-item" data-v-8a445198>LLM</span></i></div></div> <div class="theme-reco-content content__default"><h2 id="介绍"><a href="#介绍" class="header-anchor">#</a> 介绍</h2> <p>2024 年 1 月 17 日，新一代大语言模型书生·浦语 2.0（InternLM2）正式发布（<a href="https://github.com/InternLM/InternLM" target="_blank" rel="noopener noreferrer">GitHub 仓库地址<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>）。相比于第一代 InternLM，InternLM2 在推理、对话体验等方面的能力全面提升，工具调用能力整体升级，并支持 20 万字超长上下文，实现长文对话 “大海捞针”。</p> <p>InternLM2 包含 InternLM2-7B 和 InternLM2-20B 两种模型规格（20B 模型比 7B 模型功能更强大），每种规格又根据不同的应用场景，分为以下四种模型：<strong>InternLM2-Base</strong>、<strong>InternLM2</strong>、<strong>InternLM2-Chat-SFT</strong> 和 <strong>InternLM2-Chat</strong>。其中 <strong>InternLM2</strong> 是官方推荐使用的基础模型，<strong>InternLM2-Chat</strong> 是官方推荐使用的对话模型。下文主要介绍 <strong>InternLM2-Chat-7B</strong> 模型的部署和使用。</p> <table><thead><tr><th>模型</th> <th>HuggingFace</th> <th>ModelScope</th></tr></thead> <tbody><tr><td><strong>InternLM2-Chat-7B</strong></td> <td><a href="https://huggingface.co/internlm/internlm2-chat-7b" target="_blank" rel="noopener noreferrer">仓库地址<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td> <td><a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-7b/summary" target="_blank" rel="noopener noreferrer">仓库地址<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr> <tr><td><strong>InternLM2-Chat-20B</strong></td> <td><a href="https://huggingface.co/internlm/internlm2-chat-20b" target="_blank" rel="noopener noreferrer">仓库地址<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td> <td><a href="https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-20b/summary" target="_blank" rel="noopener noreferrer">仓库地址<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></td></tr></tbody></table> <h2 id="环境准备"><a href="#环境准备" class="header-anchor">#</a> 环境准备</h2> <p><a href="https://featurize.cn/" target="_blank" rel="noopener noreferrer">Featurize<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 算力平台提供了高效便捷的在线实验环境，在平台上租用合适的 GPU 实例，部署大模型，方便快捷，省时省力，而且价格亲民。</p> <p>本人实际部署 <strong>InternLM2-Chat-7B</strong> 模型消耗显存 20 GB 左右（受实际参数配置影响，仅供参考），因此租用一张 RTX 3090 或者 RTX 4090 的 GPU 实例就能满足模型运行条件。</p> <p>关于 Featurize 平台的使用，建议直接阅读 <a href="https://docs.featurize.cn/docs/manual/instance-rent" target="_blank" rel="noopener noreferrer">官方文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，上手操作非常简单，在此不在赘述。</p> <h2 id="模型部署-使用"><a href="#模型部署-使用" class="header-anchor">#</a> 模型部署&amp;使用</h2> <h3 id="页面交互方式"><a href="#页面交互方式" class="header-anchor">#</a> 页面交互方式</h3> <p>两种部署方式只是页面展示效果不同，并无本质区别，选择其中一种方式部署即可。</p> <h4 id="gradio"><a href="#gradio" class="header-anchor">#</a> Gradio</h4> <p><a href="https://github.com/InternLM/LMDeploy" target="_blank" rel="noopener noreferrer">LMDeploy<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 工具中封装了 Gradio，我们使用该工具部署模型。</p> <p>LMDeploy 所需的运行环境和模型部署代码已整理到下方的脚本文件中，执行脚本文件即可<strong>一键部署</strong>。</p> <p>首先解释下启动命令中的几个参数含义，各参数取值可根据硬件条件自行调整。</p> <ul><li><code>tp（tensor_parallel_size）</code>：表示使用几张 GPU 来运行一个模型。</li> <li><code>max_batch_size</code>：批处理大小，该参数值越大，吞吐量越高，但会占用更多显存。</li> <li><code>cache_max_entry_count</code>：设置 k/v 缓存大小，会占用显存。当值为 0~1 之间的小数时，表示 k/v block 使用的内存百分比（例如显存 60 G，该值设置为 0.5，则 k/v 使用的内存总量为 60 * 0.5 = 30G）。当值 &gt;1 时，表示 k/v block 数量。</li> <li><code>./internlm2-chat-7b</code>：模型本地存储路径。</li></ul> <p>具体操作步骤如下。</p> <ol><li>通过 ssh 终端连接到服务器实例，新建 <code>deploy.sh</code> 脚本文件，文件内容如下。</li></ol> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code><span class="token builtin class-name">cd</span> ~
<span class="token comment"># 安装运行环境</span>
<span class="token builtin class-name">echo</span> <span class="token string">&quot;Installing Python dependencies&quot;</span>
pip <span class="token function">install</span> lmdeploy socksio <span class="token assign-left variable">gradio</span><span class="token operator">==</span><span class="token number">3.50</span>.2
​
<span class="token comment"># 安装 Git ltf 扩展包</span>
<span class="token builtin class-name">echo</span> <span class="token string">&quot;Installing git lfs extension&quot;</span>
<span class="token function">curl</span> <span class="token parameter variable">-s</span> https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">bash</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> git-lfs
<span class="token function">git</span> lfs <span class="token function">install</span>
​
<span class="token comment"># 拉取模型库</span>
<span class="token builtin class-name">echo</span> <span class="token string">&quot;Download repo&quot;</span>
<span class="token function">git</span> clone https://huggingface.co/internlm/internlm2-chat-7b
​
<span class="token comment"># 启动模型</span>
<span class="token builtin class-name">echo</span> <span class="token string">&quot;start model&quot;</span>
python3 <span class="token parameter variable">-m</span> lmdeploy.serve.gradio.app <span class="token parameter variable">--tp</span><span class="token operator">=</span><span class="token number">1</span> <span class="token parameter variable">--max_batch_size</span><span class="token operator">=</span><span class="token number">64</span> <span class="token parameter variable">--cache_max_entry_count</span><span class="token operator">=</span><span class="token number">0.1</span> <span class="token parameter variable">--server_name</span><span class="token operator">=</span><span class="token number">0.0</span>.0.0 <span class="token parameter variable">--server_port</span><span class="token operator">=</span><span class="token number">8888</span> ./internlm2-chat-7b
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p>2.  执行 <code>sh deploy.sh</code> 命令启动脚本。脚本执行大约需要 5 分钟时间（模型仓库中有几个大文件）。新开一个终端窗口，执行命令 <code>watch -n 1 nvidia-smi</code> 可以实时观察 GPU 资源的使用情况。</p> <p><img src="https://s2.loli.net/2024/01/26/GH3XtiEcfK2haOY.png" alt="internLM2-01.png"></p> <ol><li>模型部署完成，执行下面命令，开放 Featurize 端口。端口开放后 Featurize 会提供公网访问地址。</li></ol> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code><span class="token comment"># 开放端口</span>
featurize port <span class="token builtin class-name">export</span> <span class="token number">8888</span>
<span class="token comment"># 查看已开放的端口</span>
featurize port list
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>4.  访问公网地址，使用模型。</p> <p><img src="https://s2.loli.net/2024/01/26/i8pgJ2YQRBIKZxL.png" alt="internLM2-02.png"></p> <h4 id="streamlit"><a href="#streamlit" class="header-anchor">#</a> Streamlit</h4> <p>官方 <a href="https://github.com/InternLM/InternLM" target="_blank" rel="noopener noreferrer">GitHub 仓库<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a> 中提供了使用 Streamlit 部署模型的代码。示例代码默认加载远程 Hugging Face 仓库中的模型，如果已经将模型下载到本地，可以修改源码从本地加载模型。</p> <p>脚本文件如下，可直接执行，一键部署。</p> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code><span class="token builtin class-name">cd</span> ~
​
<span class="token comment"># 安装环境</span>
pip <span class="token function">install</span> <span class="token assign-left variable">streamlit</span><span class="token operator">==</span><span class="token number">1.24</span>.0
pip <span class="token function">install</span> <span class="token assign-left variable">transformers</span><span class="token operator">==</span><span class="token number">4.37</span>.0
​
<span class="token comment"># 克隆代码</span>
<span class="token function">git</span> clone https://github.com/InternLM/InternLM.git
​
<span class="token comment"># 运行</span>
streamlit run ./InternLM/chat/web_demo.py
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>默认启动端口：8501，记得开放 Featurize 端口。交互页面如下所示。</p> <p><img src="https://s2.loli.net/2024/01/26/reR23oAXtnk1LKb.png" alt="internLM2-03.png"></p> <h3 id="代码方式"><a href="#代码方式" class="header-anchor">#</a> 代码方式</h3> <p><strong>注意</strong>：代码中<code>./internlm2-chat-7b</code> 为模型本地存储路径，请根据实际情况自行调整。</p> <h4 id="transformers"><a href="#transformers" class="header-anchor">#</a> Transformers</h4> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM
​
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment"># 没有本地模型，替换为 internlm/internlm2-chat-7b</span>
    tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;./internlm2-chat-7b&quot;</span><span class="token punctuation">,</span> trust_remote_code<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;./internlm2-chat-7b&quot;</span><span class="token punctuation">,</span> device_map<span class="token operator">=</span><span class="token string">&quot;auto&quot;</span><span class="token punctuation">,</span>
                                                  trust_remote_code<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">)</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    response<span class="token punctuation">,</span> history <span class="token operator">=</span> model<span class="token punctuation">.</span>chat<span class="token punctuation">(</span>tokenizer<span class="token punctuation">,</span> <span class="token string">&quot;你好 我是 Cleaner&quot;</span><span class="token punctuation">,</span> history<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h4 id="modelscope"><a href="#modelscope" class="header-anchor">#</a> ModelScope</h4> <div class="language-py line-numbers-mode"><pre class="language-py"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> modelscope <span class="token keyword">import</span> snapshot_download<span class="token punctuation">,</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM
​
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment"># 没有本地模型，替换为 Shanghai_AI_Laboratory/internlm2-chat-7b</span>
    model_dir <span class="token operator">=</span> snapshot_download<span class="token punctuation">(</span><span class="token string">'./internlm2-chat-7b'</span><span class="token punctuation">)</span>
    tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_dir<span class="token punctuation">,</span> device_map<span class="token operator">=</span><span class="token string">&quot;auto&quot;</span><span class="token punctuation">,</span> trust_remote_code<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_dir<span class="token punctuation">,</span> device_map<span class="token operator">=</span><span class="token string">&quot;auto&quot;</span><span class="token punctuation">,</span> trust_remote_code<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                                  torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">)</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    response<span class="token punctuation">,</span> history <span class="token operator">=</span> model<span class="token punctuation">.</span>chat<span class="token punctuation">(</span>tokenizer<span class="token punctuation">,</span> <span class="token string">&quot;你好 我是 Cleaner&quot;</span><span class="token punctuation">,</span> history<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><h4 id="lmdeploy"><a href="#lmdeploy" class="header-anchor">#</a> LMDeploy</h4> <p><a href="https://lmdeploy.readthedocs.io/zh-cn/latest/inference/pipeline.html#id1" target="_blank" rel="noopener noreferrer">LMDeploy 使用文档<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <div class="language-py line-numbers-mode"><pre class="language-py"><code><span class="token keyword">from</span> lmdeploy <span class="token keyword">import</span> pipeline<span class="token punctuation">,</span> TurbomindEngineConfig
​
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    backend_config <span class="token operator">=</span> TurbomindEngineConfig<span class="token punctuation">(</span>tp<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                                            max_batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>
                                            cache_max_entry_count<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
    <span class="token comment"># 没有本地模型，替换为 internlm/internlm2-chat-7b</span>
    pipe <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">&quot;./internlm2-chat-7b&quot;</span><span class="token punctuation">,</span> backend_cofing<span class="token operator">=</span>backend_cofing<span class="token punctuation">)</span>
    response <span class="token operator">=</span> pipe<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">&quot;你好 我是 Cleaner&quot;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><h2 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h2> <p>梳理 InternLM2 的特点，帮助想要使用大语言模型的个人开发者或者企业，在面对众多大语言模型时，能够了解大语言模型提供的能力，并结合自身的需求与成本，做出清晰明确的选择。</p> <ul><li>开源免费、可商用。</li> <li>超长上下文支持：200K token 的输入与理解。（书籍等大文本数据做摘要总结、若干轮对话后回忆之前的内容（大海捞针））</li> <li>支持工具调用能力：能够在一次交互中多次调用工具，完成相对复杂的任务。（Agent）</li> <li>支持微调和训练。（提供专有数据集，打造个人/企业私有化大模型）。</li></ul> <h2 id="末尾"><a href="#末尾" class="header-anchor">#</a> 末尾</h2> <p>作为一名软件开发人员，大模型的相关应用已经成为我日常工作和生活中的常用工具，本人也在不断跟进了解人工智能的发展情况。</p> <p>大模型从对话、聊天到工具调用、长文理解，乃至多模态，在不断打破人类认知，带给我们无限的想象空间。</p> <p>也许未来的某一天，我们可以拥有自己的贾维斯（Friday）。</p></div></section> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev"><a href="/llm/basicOne.html" class="prev">
          发展历程、构建过程及如何使用
        </a></span> <!----></p></div> <div class="comments-wrapper"><!----></div></main></div> <!----></div> <ul class="sub-sidebar sub-sidebar-wrapper" style="width:12rem;" data-v-b57cc07c data-v-7dd95ae2><li class="level-2" data-v-b57cc07c><a href="/llm/InternLM2.html#介绍" class="sidebar-link reco-side-介绍" data-v-b57cc07c>介绍</a></li><li class="level-2" data-v-b57cc07c><a href="/llm/InternLM2.html#环境准备" class="sidebar-link reco-side-环境准备" data-v-b57cc07c>环境准备</a></li><li class="level-2" data-v-b57cc07c><a href="/llm/InternLM2.html#模型部署-使用" class="sidebar-link reco-side-模型部署-使用" data-v-b57cc07c>模型部署&amp;使用</a></li><li class="level-3" data-v-b57cc07c><a href="/llm/InternLM2.html#页面交互方式" class="sidebar-link reco-side-页面交互方式" data-v-b57cc07c>页面交互方式</a></li><li class="level-3" data-v-b57cc07c><a href="/llm/InternLM2.html#代码方式" class="sidebar-link reco-side-代码方式" data-v-b57cc07c>代码方式</a></li><li class="level-2" data-v-b57cc07c><a href="/llm/InternLM2.html#总结" class="sidebar-link reco-side-总结" data-v-b57cc07c>总结</a></li><li class="level-2" data-v-b57cc07c><a href="/llm/InternLM2.html#末尾" class="sidebar-link reco-side-末尾" data-v-b57cc07c>末尾</a></li></ul></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div><!----><!----><!----></div></div>
    <script src="/assets/js/app.96fa03ec.js" defer></script><script src="/assets/js/3.6d0f9571.js" defer></script><script src="/assets/js/1.2ae15e76.js" defer></script><script src="/assets/js/30.5d03341f.js" defer></script><script src="/assets/js/9.5e3ddfef.js" defer></script>
  </body>
</html>
